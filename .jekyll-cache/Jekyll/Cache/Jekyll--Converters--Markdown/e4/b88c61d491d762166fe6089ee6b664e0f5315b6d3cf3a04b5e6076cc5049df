I"≠%<!-- # Research Domains
<br>
<span style="color:blue"><b>Architecture and Neuroscience</b></span>  
*How can we quantify the impact of architectural design features on human experience? Can we use the findings to improve the design practice for better and healtier experiences in the built environment?*  

<span style="color:blue"><b>Urban Challenges for AEC/FM</b></span>  
*How can the design, construction and facilities management processes be improved to tackle with  the challenges imposed by urban settings?*  

<span style="color:blue"><b>Understanding the context under which Civil Infrastructure Systems (CIS) operate</b></span>  
*How sensors and models can be integrated to better understand system behaviors?*  

<span style="color:blue"><b>Healthier building systems</b></span>  
*How can the performance of interconnected facility systems  be determined for setting proactive management strategies?*  

<b>Testbeds utilized</b>: legacy and smart buildings, airports, highways.  

<b>Tools utilized</b>: Building information models, data driven methodologies, advanced visualization
<br><br><br> -->
<h1 id="current-projects">Current Projects</h1>
<p>Click images to see more details about projects.</p>

<div class="row">

  <div class="col-sm-6 clearfix">
    <div class="well">
      <pubtit>Data-driven Building and Urban Energy Efficiency for Sustainable Cities</pubtit>
      <p><a href="http://0.0.0.0:4000/projects/data-driven-building-urban-energy"><img src="/images/pubpic/prj_qi.jpeg" alt="" class="img-responsive" /></a>
  <!-- <p>This project aims to identify energy efficiency in buildings and communities at an urban scale. Leveraging publicly accessible datasets, a data-driven approach is employed, utilizing computer vision and spatial analysis techniques. The objective is to provide technical support for energy-saving retrofits in buildings and to achieve urban energy conservation and emission reduction goals. This endeavor contributes to the broader discourse on sustainable urban development and energy conservation. The findings from this research could potentially influence policy-making and urban planning, leading to more energy-efficient and sustainable urban environments.</p> --></p>
    </div>
  </div>

  <div class="col-sm-6 clearfix">
    <div class="well">
      <pubtit>Sensor-enabled Calibration of VR-Integrated Co-Simulation Platforms for Enhanced Accuracy in Multi-modal Mobility Models</pubtit>
      <p><a href="http://0.0.0.0:4000/projects/sensor-enabled-mobility"><img src="/images/pubpic/prj_shuo.jpeg" alt="" class="img-responsive" /></a>
  <!-- <p>Traffic simulations provide valuable insights into traffic control measures, infrastructure design, vehicle-to-vehicle communication, route selection behavior, emissions modeling, and more. SUMO (Simulation of Urban MObility), an open-source, microscopic, and multimodal traffic flow simulation platform, facilitates the creation of realistic traffic flow simulations by incorporating road networks, vehicles, pedestrians, and interactions with other applications such as virtual reality platforms and driver simulators. Calibration aims to bridge the gap between simulation outcomes and real-world observations; however, the effectiveness of calibration relies heavily on the realism of interactive behavior models for various agents, such as cars, drivers, bicyclists, pedestrians (including those with accessibility needs), and workers. Integrating multiple interactive simulations into a coherent representation of real-world transportation settings poses significant challenges due to the complexities of microsimulation, the diverse range of metrics, and varying traffic control systems. Calibration metrics, data sources, temporal scales, and spatial versus perceptual accuracies vary among platforms, leading to complexities when synchronizing and calibrating them collectively.</p> --></p>
    </div>
  </div>

</div>

<div class="row">

  <div class="col-sm-6 clearfix">
    <div class="well">
      <pubtit>A BIM-based approach for improving building fa√ßade inspection in cities</pubtit>
      <p><a href="http://0.0.0.0:4000/projects/urban-facade-inspection"><img src="/images/pubpic/prj3.png" alt="" class="img-responsive" /></a>
  <!-- <p>For highly and densely populated cities like New York City, fa√ßade inspection is a mandatory routine every 5 years for buildings that have more than 6 floors. The current inspection is mainly based on visual checks, and the results are based on the inspectors‚Äô experience. The objectives of this research are (1) to identify the required information for the decision-making of fa√ßade inspection and (2) to support the fa√ßade inspection process with a model-based  generation of comprehensive checklists and flexible visualization of inspection findings.</p> --></p>
    </div>
  </div>

  <div class="col-sm-6 clearfix">
    <div class="well">
      <pubtit>Intelligent Wearable Warning Devices for Improving Roadway Worker Safety</pubtit>
      <p><a href="http://0.0.0.0:4000/projects/work-zone-safety"><img src="/images/pubpic/prj7_worker_safety.png" alt="" class="img-responsive" /></a>
  <!-- <p>In the United States, fatalities resulting from vehicular crashes in roadway work zones have recently peaked to over 900 deaths in a single year. Research has investigated many contributing factors (vehicle motorist, environment), but has yet to study how roadway workers' physically react (e.g., evade body, turn head direction) to hazardous traffic vehicles (e.g., speeding, intrusion). Meanwhile, industry developments have proposed work zone alert systems that detect hazardous vehicles near the construction area and raise alarms (e.g., sounds, lights) for roadway workers from a stationary device. While wearable warning devices can improve on current stationary alert systems, there remains a lack of understanding of how roadway workers will respond to alarms with different attributes (e.g., modality, duration). Roadway workers can also experience alarm fatigue, becoming less responsive (e.g., slower reaction time, less attention to hazards) from repeatedly receiving the same alarms. To address these challenges, this research project seeks to develop an intelligent wearable warning system that raises alarms on an individual worker's body, based on how workers naturally behave in roadway work zones and which alarm attributes can ensure their long-term overall safety. This project will utilize a wearable sensor and virtual reality (VR) roadway work zone simulation platform to collect data on how  workers physically react to different hazardous vehicles and various attributes of alarms emitted by a wearable device. The collected data will then be used to: 1) develop a deep learning model (i.e., transformer) for accurately predicting a worker‚Äôs behavior towards hazardous vehicles, absent any alarms, 2) identify a list of attributes of wearable alarms that are effective in improving worker safety, 3) evaluate a deep reinforcement learning-based (i.e., deep Q-network) alarm control algorithm for modifying wearable alarm attributes to counteract long-term alarm fatigue. These investigations will advance the future development of wearable warning devices for improving roadway construction workers' safety from vehicular crashes.</p> --></p>
    </div>
  </div>

</div>

<div class="row">

  <div class="col-sm-6 clearfix">
    <div class="well">
      <pubtit>AI-powered and Robot-assisted Manufacturing for Modular Construction: Train module assembly progress inference AI model training in Virtual Reality</pubtit>
      <p><a href="http://0.0.0.0:4000/projects/arm4mod"><img src="/images/pubpic/prj8_kpark.png" alt="" class="img-responsive" /></a>
  <!-- <p>Modular construction aims at overcoming challenges faced by the traditional construction process such as the shortage of skilled workers, fast-track project requirements, and cost associated with on-site productivity losses and recurrent rework. Since manufacturing is done off-site in controlled factory settings, modular construction is associated with increased productivity and better quality control. However, because every construction project is unique and results in distinct work pieces and building elements to be assembled, modular construction factories necessitate better mechanisms to assist workers during the assembly process in order to minimize errors in selecting the pieces to be assembled and idle times while figuring out the next step in an assembly sequence. Machine intelligence provides opportunities for such assistance; however, a challenge is to rapidly generate large datasets with rich contextual data to train such intelligent agents. This work overviews a mechanism to generate such datasets in virtual environments and evaluates the performance of AI models trained using data generated in virtual environments in recognizing the next installation step in modular assembly sequences. Performance of the trained MV-CNN models (with accuracy of 0.97) shows that virtual environments can potentially be used to generate the required datasets for AI without the costly, time-consuming, and labor-intensive investments needed upfront for capturing real-world data.</p> --></p>
    </div>
  </div>

  <div class="col-sm-6 clearfix">
    <div class="well">
      <pubtit>AI-based semantic generative design models for architectural layout design</pubtit>
      <p><a href="http://0.0.0.0:4000/projects/ai-arch"><img src="/images/pubpic/prj9_kpark.png" alt="" class="img-responsive" /></a>
  <!-- <p></p> --></p>
    </div>
  </div>

</div>

<p><br /></p>
:ET