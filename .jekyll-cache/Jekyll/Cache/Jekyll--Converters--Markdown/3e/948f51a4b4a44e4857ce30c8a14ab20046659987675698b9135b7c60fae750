I"·.<!-- # Research Domains
<br>
<span style="color:blue"><b>Architecture and Neuroscience</b></span>  
*How can we quantify the impact of architectural design features on human experience? Can we use the findings to improve the design practice for better and healtier experiences in the built environment?*  

<span style="color:blue"><b>Urban Challenges for AEC/FM</b></span>  
*How can the design, construction and facilities management processes be improved to tackle with  the challenges imposed by urban settings?*  

<span style="color:blue"><b>Understanding the context under which Civil Infrastructure Systems (CIS) operate</b></span>  
*How sensors and models can be integrated to better understand system behaviors?*  

<span style="color:blue"><b>Healthier building systems</b></span>  
*How can the performance of interconnected facility systems  be determined for setting proactive management strategies?*  

<b>Testbeds utilized</b>: legacy and smart buildings, airports, highways.  

<b>Tools utilized</b>: Building information models, data driven methodologies, advanced visualization
<br><br><br> -->
<h1 id="current-projects">Current Projects</h1>
<p>Click images to see more details about projects.</p>

<div class="row">

  <div class="col-sm-6 clearfix">
    <div class="well">
      <pubtit>Building grid interactions: Improving demand-response performance of buildings through accurate electricity demand estimations</pubtit>
      <p><a href="/projects/building-grid-interactions"><img src="/images/pubpic/prj1.jpg" alt="" class="img-responsive" /></a>
  <!-- <p>This research project is about understanding how to improve the efficiency of DR implementation in buildings and how to improve the accuracy of the electricity saving potential estimates of buildings that are participating in DR programs. We are approaching this problem by (1) examining  a large pool of DR protocols in terms of the building information needed in each protocol and look at how building information models can help to streamline access to facility information; (2) automatically extracting synthesized DR related building information from existing BIMs; and (3) estimating the true saving potential of buildings by applying advanced data analysis techniques (e.g., machine learning, deep learning).</p> --></p>
    </div>
  </div>

  <div class="col-sm-6 clearfix">
    <div class="well">
      <pubtit>Emotionally intelligent buildings: Responsive virtual environments using biometric sensing</pubtit>
      <p><a href="/projects/emotionally-intelligent-buildings"><img src="/images/pubpic/prj2.png" alt="" class="img-responsive" /></a>
  <!-- <p>This project aims to quantitatively measure human experience in designed spaces and create responsive virtual environments. It builds of off findings of a recent DARPA project on neuroscience for architecture where requirements for designed spaces for boosting human experience were defined. The responsive environments are generated using labeled emotions of users in biometric sensor data captured while users navigate in virtual spaces.  The three-step approach includes (1) automatically checking BIM of a new design against requirements for enhanced human experience in designed spaces, (2) automatically labeling human experiences on the arousal and valence scale using biometric data captured in distinctly configured virtual spaces, (3) developing reasoning mechanisms to transform spaces based on the streaming BSN data. This research aims to provide the much-needed design guidelines for architects to follow when designing spaces with human experience in mind.</p> --></p>
    </div>
  </div>

</div>

<div class="row">

  <div class="col-sm-6 clearfix">
    <div class="well">
      <pubtit>Urban facade inspection: Computer-vision based condition assessment of building facades captured through LIDAR</pubtit>
      <p><a href="/projects/urban-facade-inspection"><img src="/images/pubpic/prj3.png" alt="" class="img-responsive" /></a>
  <!-- <p>For high densely populated cities like the New York City, faÃ§ade inspection is a mandatory routine every 5 years for the buildings that have more than 6 floors. The current inspection are mainly based on visual check and the results are based on the inspectorsâ€™ experience. The objectives of this research are (1) to identify the required information for the decision making of faÃ§ade inspection and (2) support the faÃ§ade inspection process with an objective way of detecting faÃ§ade defects using point clouds.</p> --></p>
    </div>
  </div>

  <div class="col-sm-6 clearfix">
    <div class="well">
      <pubtit>Customized building operations: Defining operational signatures of HVAC system configurations through data analytics on historical BAS data</pubtit>
      <p><a href="/projects/customized-building-operations"><img src="/images/pubpic/prj4.png" alt="" class="img-responsive" /></a>
  <!-- <p>This study aims to identify critical parameters of HVAC systems that drive the changes in the building energy-use profiles and develop an automated approach for identifying HVAC operational signatures that result in certain energy profiles in buildings, OperAtional Signature Identification System (OASIS). The OASIS relies on data-driven methodologies and is composed of three major steps: data preprocessing, feature selection, and signature discovery and analysis. The approach was tested on several air handling units (AHUs). The results showed that it is possible to define operational signatures for facility operators that are specific to a given building for running AHUs at these custom settings that correspond to energy efficient consumption in buildings.</p> --></p>
    </div>
  </div>

</div>

<div class="row">

  <div class="col-sm-6 clearfix">
    <div class="well">
      <pubtit>Neuroscience for architecture: Quantification of impact of architecture on human experience in the built environment</pubtit>
      <p><a href="/projects/neuroscience-for-architecture"><img src="/images/pubpic/prj5.png" alt="" class="img-responsive" /></a>
  <!-- <p>The impact of built environment on the human responsiveness and performance has long been argued; however, the interrelations between neuroscience and built environment, and the degree to which the built environment contributes to increased human performance and context awareness has not been completely understood yet.  Towards this understanding,this project is at the intersection of Neuroscience and Architecture to quantify the impact of architectural design features on human performance and experience. This project utilizes advanced visualization, virtual reality and body area sensor networks to capture human bodily states while people interact with architectural layouts in virtual settings.</p> --></p>
    </div>
  </div>

  <div class="col-sm-6 clearfix">
    <div class="well">
      <pubtit>Increasing Work Zone Safety: Worker Behavioral Analysis with Integration of Wearable Sensors and Virtual Reality</pubtit>
      <p><a href="/projects/increasing-work-zone-safety"><img src="/images/pubpic/prj6.png" alt="" class="img-responsive" /></a>
  <!-- <p>According to the Federal Highway Administration (FHWA), work zone fatalities at road construction projects account for up to 3% of all workplace fatalities in a given year [1], and the primary causes are runovers/backovers, collisions, and caught in-between mobile equipment. One of the main proactive approaches adopted by construction companies to prevent these incidents is safety training courses, which are designed to help increase workersâ€™ awareness of hazards around the job sites and take timely actions to avoid injuries. However, work zone safety knowledge from training courses is not enough to change the level of vigilance of workers, which is easily affected by factors such as fatigue or environmental distractions. With the development of wearable technologies, an increasing number of research studies have been exploring the feasibility of using wearable sensors to detect workersâ€™ attention and vigilance towards job site hazards. However, merely measuring workersâ€™ awareness of hazards is not sufficient. There is still a need to understand key parameters that impact worker and driver behaviors regarding received alarms/warnings/notifications and design notification systems that are calibrated for the optimal time, frequency, and modality to push information on potential hazards at work zones. With the goal of reducing the number of injuries and fatalities, this project aims to understand the key parameters (e.g., work zone location characteristics, personal vigilance levels, types of construction work) that play roles in achieving responsive behaviors in workers. Key questions this research will address include in what conditions people ignore or respond to warnings, how notification systems can be calibrated for getting responsive actions from workers, and what modalities, frequencies, and timings of pushing notifications are most effective. Through wearable sensors and realistic representations of work zones in virtual reality, we plan to collect worker behavioral and physiological (heart rate) responses to warnings issued under various realistic scenarios and various warning mechanisms.</p> --></p>
    </div>
  </div>

</div>

<div class="row">

  <div class="col-sm-6 clearfix">
    <div class="well">
      <pubtit>Work Zone Safety III: Calibration of Safety Notifications through Reinforcement Learning and Eye Tracking</pubtit>
      <p><a href="/projects/work-zone-safety"><img src="/images/pubpic/prj7.png" alt="" class="img-responsive" /></a>
  <!-- <p>According to the Federal Highway Administration (FHWA), work zone fatalities at road construction projects account for up to 3% of all workplace fatalities in a given year [1], and the primary causes are runovers/backovers, collisions, and caught in-between mobile equipment. Hence, drivers and the way they perceive the work zone and related notifications are primary factors required to reduce fatalities. A study of work zone crash data in five states showed that around half of the crashes occur within or adjacent to work activities, putting workers in danger together with drivers [2]. To reduce work zone injuries and fatalities, regulations such as mandated Personal Protective Equipment (PPE), traffic control plans, advance warning signs, the share of traveler information, and signal timing adjustments (ANSI, OSHA) were introduced by the regulatory bodies. However, these mainly aim for changing the behavior of drivers instead of workers. Although there is a large body of analysis and modeling literature related to work zone accidents as documented in [3], the actual safety treatments applicable to real-world work zones are limited at best and there is still a need for proactive approaches to be deployed at highway work zones, capable of warning construction workers of approaching hazards in advance.
To improve work zone safety, in the previous two phases of this project, we proposed a virtual reality (VR)-based platform that integrates with SUMO and hardware in the loop sensors to realistically simulate dangerous situations in work zones (i.e., enabling worker-initiated changes in the work zone to be accounted in SUMO and updated simulation to be displayed real-time in VR). In this phase, we propose to add two main components to the existing VR work zone safety testing platform. The first component focuses on monitoring construction workersâ€™ attention. To that end, we propose adding new functionality to the current VR platform to track the subjectsâ€™ attention through his/her head-movement and eye-movement to infer his/her gaze pattern. With the introduction of this method to measure the subjectâ€™s attention, we plan to capture additional critical information about the decision a worker makes.</p> --></p>
    </div>
  </div>

</div>

<p><br /></p>
:ET