- title: "Building grid interactions: Improving demand-response performance of buildings through accurate electricity demand estimations"
  image: prj1.jpg
  addr: building-grid-interactions
  pp:
    pp1: "Yu, X., and Ergan, S. (2018). “BIM coverage in demand response management: a pilot study in campus buildings.” In Construction Research Congress 2018, pp. 316-325, April 2-4, 2018, New Orleans, LA, U.S.A. DOI: https://ascelibrary.org/doi/abs/10.1061/9780784481264.031"
    pp2: "Yu, X., and Ergan, S. (2018). “A data-driven framework to estimate saving potential of buildings in demand response events.” In ISARC. Proceedings of the International Symposium on Automation and Robotics in Construction, IAARC Publications, Vol. 35, pp. 1-8, July 20-25, 2018, Berlin, German. DOI: https://doi.org/10.22260/ISARC2018/0145"
    pp3: "Yu, X., and Ergan, S. (2019). “Identification of principal factors in determining building peak energy shaving capacities during demand response events.” In The 2019 ASCE International Conference on Computing in Civil Engineering, June 17-19, 2019, Atlanta, GA, U.S.A."
  description: This research project is about understanding how to improve the efficiency of DR implementation in buildings and how to improve the accuracy of the electricity saving potential estimates of buildings that are participating in DR programs. We are approaching this problem by (1) examining  a large pool of DR protocols in terms of the building information needed in each protocol and look at how building information models can help to streamline access to facility information; (2) automatically extracting synthesized DR related building information from existing BIMs; and (3) estimating the true saving potential of buildings by applying advanced data analysis techniques (e.g., machine learning, deep learning).
  highlight: 1
  news2:

- title: "Emotionally intelligent buildings: Responsive virtual environments using biometric sensing"
  image: prj2.png
  addr: emotionally-intelligent-buildings
  pp:
  description: This project aims to quantitatively measure human experience in designed spaces and create responsive virtual environments. It builds of off findings of a recent DARPA project on neuroscience for architecture where requirements for designed spaces for boosting human experience were defined. The responsive environments are generated using labeled emotions of users in biometric sensor data captured while users navigate in virtual spaces.  The three-step approach includes (1) automatically checking BIM of a new design against requirements for enhanced human experience in designed spaces, (2) automatically labeling human experiences on the arousal and valence scale using biometric data captured in distinctly configured virtual spaces, (3) developing reasoning mechanisms to transform spaces based on the streaming BSN data. This research aims to provide the much-needed design guidelines for architects to follow when designing spaces with human experience in mind.
  highlight: 1
  news2:

- title: "Urban facade inspection: Computer-vision based condition assessment of building facades captured through LIDAR"
  image: prj3.png
  addr: urban-facade-inspection
  pp:
    pp1: "Shi, Z., and Ergan, S. (2019). “”, 4th International Conference on Civil and Building Engineering Informatics, ICCBEI, Sendai, Japan, November 7-8, 2019. (abstract submitted)."
    pp2: "Shi, Z., and Ergan, S. (2018). “Leveraging point cloud data for detecting building façade deteriorations caused by neighboring construction.” 5th International Project and Construction Management Conference (IPCMC), Cyprus, November 16-18, 2018."
  description: For high densely populated cities like the New York City, façade inspection is a mandatory routine every 5 years for the buildings that have more than 6 floors. The current inspection are mainly based on visual check and the results are based on the inspectors’ experience. The objectives of this research are (1) to identify the required information for the decision making of façade inspection and (2) support the façade inspection process with an objective way of detecting façade defects using point clouds.
  highlight: 1
  news2:

- title: "Customized building operations: Defining operational signatures of HVAC system configurations through data analytics on historical BAS data"
  image: prj4.png
  addr: customized-building-operations
  pp:
    pp1: "Dedemen, G., and Ergan, S. (2018). “Quantifying performance degradation of HVAC systems for proactive maintenance using a data-driven approach.” 25th International Workshop on Intelligent Computing in Engineering (EG-ICE), June 10-13, 2018, Lausanne, Switzerland. DOI: https://link.springer.com/chapter/10.1007/978-3-319-91635-4_25."
    pp2: "Dedemen, G., Vakilinezhad, M. and Ergan, S. (2017). “Using data driven methodologies to identify patterns in BAS data to support facility operations.” International Workshop of Computing in Civil Engineering, June 25-27, 2017, Seattle, WA, pp. 282-289. DOI: https://doi.org/10.1061/9780784480823.034."
    pp3: "Dedemen, G., and Ergan, S. (2017). “Towards energy efficient operational patterns in Air Handling Units in highly sensed buildings.” 24th International Workshop on Intelligent Computing in Engineering -EG-ICE (2017), July 10-12, 2017, Nottingham, UK, pp. 45-54. DOI: https://www.nottingham.ac.uk/conference/fac-eng/eg-ice2017."
  description: 'This study aims to identify critical parameters of HVAC systems that drive the changes in the building energy-use profiles and develop an automated approach for identifying HVAC operational signatures that result in certain energy profiles in buildings, OperAtional Signature Identification System (OASIS). The OASIS relies on data-driven methodologies and is composed of three major steps: data preprocessing, feature selection, and signature discovery and analysis. The approach was tested on several air handling units (AHUs). The results showed that it is possible to define operational signatures for facility operators that are specific to a given building for running AHUs at these custom settings that correspond to energy efficient consumption in buildings.'
  highlight: 1
  news2:

- title: "Neuroscience for architecture: Quantification of impact of architecture on human experience in the built environment"
  image: prj5.png
  addr: neuroscience-for-architecture
  pp:
    pp1: "Zou, Z., Yu, X., and Ergan, S. (2019). “Integrating biometric sensors, VR, and machine learning to classify EEG signals in alternative architecture designs.”ASCE International Conference on Computing in Civil Engineering. June 17 – 19, 2019. Atlanta, Georgia, U.S."
    pp2: "Zou, Z., and Ergan, S. (2019). “Where do we look? An eye-tracking study of architectural features in building design.” Advances in Informatics and Computing in Civil and Construction Engineering (pp. 439-446). Springer, Cham. https://doi.org/10.1007/978-3-030-00220-6_52."
    pp3: "Zou, Z., and  Ergan, S. (2019). “A framework towards quantifying human restorativeness in virtual built environments.” EDRA 50: Sustainable Urban Environments: Research, Design and Planning for the Next 50 Years. May 22 – May 26, 2019. Brooklyn, New York, U.S."
    pp4: "Ergan, S., Radwan, A., Zou, Z., Tseng, H. A., and Han, X. (2018). “Quantifying human experience in architectural spaces with integrated virtual reality and body sensor networks.” Journal of Computing in Civil Engineering, 33(2),04018062.  https://doi.org/10.1061/(ASCE)CP.1943-5487.0000812"
    pp5: "Ergan, S., Shi, Z., and Yu, X. (2018). “Towards quantifying human experience in the built environment: A crowdsourcing based experiment to identify influential architectural design features.” Elsevier Journal of Building Engineering, 20(11), 51-59. DOI: https://doi.org/10.1016/j.jobe.2018.07.004."
    pp6: "Zou, Z., Arruda, L., and Ergan, S. (2018). “Characteristics of models that impact transformation of BIMs to virtual environments to support facility management operations.” Journal of Civil Engineering and Management, 24(6), 481-498.  https://doi.org/10.3846/jcem.2018.5689."
    pp7: "Zou, Z., and Ergan, S.(2018). “Human experience in stimulating architectural spaces: integrating VR and body sensor networks.”  ANFA Academy of Neuroscience for Architecture Annual Conference, (poster presentation), La Jolla, CA, September 20-22, 2018."
    pp8: "Radwan, A., and Ergan, S. (2017). “Quantifying human experience in interior architectural spaces.” International Workshop of Computing in Civil Engineering, June 25-27, 2017, Seattle, WA, pp. 373-380. DOI:https://doi.org/10.1061/9780784480830.046."
    pp9: "Radwan, A., and Ergan, S. (2016). “Towards quantifying the impact of the built environment on human experience: elements of experimental design.” ANFA Academy of Neuroscience for Architecture Annual Conference, (poster presentation), La Jolla, CA, September 23-24, 2016."
  description: The impact of built environment on the human responsiveness and performance has long been argued; however, the interrelations between neuroscience and built environment, and the degree to which the built environment contributes to increased human performance and context awareness has not been completely understood yet.  Towards this understanding,this project is at the intersection of Neuroscience and Architecture to quantify the impact of architectural design features on human performance and experience. This project utilizes advanced visualization, virtual reality and body area sensor networks to capture human bodily states while people interact with architectural layouts in virtual settings.
  highlight: 1  
  news2:

- title: "Increasing Work Zone Safety: Worker Behavioral Analysis with Integration of Wearable Sensors and Virtual Reality"
  image: prj6.png
  addr: increasing-work-zone-safety
  description: "According to the Federal Highway Administration (FHWA), work zone fatalities at road construction projects account for up to 3% of all workplace fatalities in a given year, and the primary causes are runovers/backovers, collisions, and caught in-between mobile equipment. One of the main proactive approaches adopted by construction companies to prevent these incidents is safety training courses, which are designed to help increase workers’ awareness of hazards around the job sites and take timely actions to avoid injuries. However, work zone safety knowledge from training courses is not enough to change the level of vigilance of workers, which is easily affected by factors such as fatigue or environmental distractions. With the development of wearable technologies, an increasing number of research studies have been exploring the feasibility of using wearable sensors to detect workers’ attention and vigilance towards job site hazards. However, merely measuring workers’ awareness of hazards is not sufficient. There is still a need to understand key parameters that impact worker and driver behaviors regarding received alarms/warnings/notifications and design notification systems that are calibrated for the optimal time, frequency, and modality to push information on potential hazards at work zones. With the goal of reducing the number of injuries and fatalities, this project aims to understand the key parameters (e.g., work zone location characteristics, personal vigilance levels, types of construction work) that play roles in achieving responsive behaviors in workers. Key questions this research will address include in what conditions people ignore or respond to warnings, how notification systems can be calibrated for getting responsive actions from workers, and what modalities, frequencies, and timings of pushing notifications are most effective. Through wearable sensors and realistic representations of work zones in virtual reality, we plan to collect worker behavioral and physiological (heart rate) responses to warnings issued under various realistic scenarios and various warning mechanisms."
  pp:
    pp1: "Bernardes, S. D., Zou, Z., Zuo, F., Ergan, S., Khan, J. A. and Ozbay, K. (2020). Development of a Virtual-Reality Based Immersive and Integrated Traffic Simulation Platform for Studying Traffic Work Zone Safety Problems. TRB 2020 annual meeting"
    pp2: "Zou, Z., Ergan, S., (2020). An Integrated Approach to Capture Construction Workers’ Response towards Safety Alarms using Wearable Sensors and Virtual Reality. C2SMART webinar series, presented on May 26th, 2020."
    pp3: "Zou, Z., Bernardes, S. D., Zuo, F., Ergan, S., and Ozbay, K. (2021). “An integrate66d approach to enable Hardware-in-the-loop for realtime VR, traffic simulation and sensor interactions: An Application in work zone safety”. Journal of Advanced Engineering Informatics."
  highlight: 1

- title: "Work Zone Safety III: Calibration of Safety Notifications through Reinforcement Learning and Eye Tracking"
  image: prj7.png
  addr: work-zone-safety
  description: "According to the Federal Highway Administration (FHWA), work zone fatalities at road construction projects account for up to 3% of all workplace fatalities in a given year, and the primary causes are runovers/backovers, collisions, and caught in-between mobile equipment. Hence, drivers and the way they perceive the work zone and related notifications are primary factors required to reduce fatalities. A study of work zone crash data in five states showed that around half of the crashes occur within or adjacent to work activities, putting workers in danger together with drivers [2]. To reduce work zone injuries and fatalities, regulations such as mandated Personal Protective Equipment (PPE), traffic control plans, advance warning signs, the share of traveler information, and signal timing adjustments (ANSI, OSHA) were introduced by the regulatory bodies. However, these mainly aim for changing the behavior of drivers instead of workers. Although there is a large body of analysis and modeling literature related to work zone accidents as documented in [3], the actual safety treatments applicable to real-world work zones are limited at best and there is still a need for proactive approaches to be deployed at highway work zones, capable of warning construction workers of approaching hazards in advance. To improve work zone safety, in the previous two phases of this project, we proposed a virtual reality (VR)-based platform that integrates with SUMO and hardware in the loop sensors to realistically simulate dangerous situations in work zones (i.e., enabling worker-initiated changes in the work zone to be accounted in SUMO and updated simulation to be displayed real-time in VR). In this phase, we propose to add two main components to the existing VR work zone safety testing platform. The first component focuses on monitoring construction workers’ attention. To that end, we propose adding new functionality to the current VR platform to track the subjects’ attention through his/her head-movement and eye-movement to infer his/her gaze pattern. With the introduction of this method to measure the subject’s attention, we plan to capture additional critical information about the decision a worker makes."
  highlight: 1

- title: "AI-powered and Robot-assisted Manufacturing for Modular Construction: Train module assembly progress inference AI model training in Virtual Reality"
  image: prj8_kpark.png
  addr: ARM4Mod
  description: "Modular construction aims at overcoming challenges faced by the traditional construction process such as the shortage of skilled workers, fast-track project requirements, and cost associated with on-site productivity losses and recurrent rework. Since manufacturing is done off-site in controlled factory settings, modular construction is associated with increased productivity and better quality control. However, because every construction project is unique and results in distinct work pieces and building elements to be assembled, modular construction factories necessitate better mechanisms to assist workers during the assembly process in order to minimize errors in selecting the pieces to be assembled and idle times while figuring out the next step in an assembly sequence. Machine intelligence provides opportunities for such assistance; however, a challenge is to rapidly generate large datasets with rich contextual data to train such intelligent agents. This work overviews a mechanism to generate such datasets in virtual environments and evaluates the performance of AI models trained using data generated in virtual environments in recognizing the next installation step in modular assembly sequences. Performance of the trained MV-CNN models (with accuracy of 0.97) shows that virtual environments can potentially be used to generate the required datasets for AI without the costly, time-consuming, and labor-intensive investments needed upfront for capturing real-world data."
  pp:
    pp1: "Park, K., & Ergan, S. (2022). Toward Intelligent Agents to Detect Work Pieces and Processes in Modular Construction: An Approach to Generate Synthetic Training Data. In Construction Research Congress 2022 (pp. 802-811)."
    pp2: "Park, K., Ergan, S., & Feng, C. (2021). Towards intelligent agents to assist in modular construction: evaluation of datasets generated in virtual environments for AI training. In ISARC. Proceedings of the International Symposium on Automation and Robotics in Construction (Vol. 38, pp. 327-333). IAARC Publications."
  highlight: 1

# - title: "AI-based semantic generative design models for architectural layout design"
#   image: prj9_kpark.png
#   addr: ai-arch
#   description: ""
#   highlight: 1